\begin{thenomenclature} 

 \nomgroup{A}

  \item [{GPU}]\begingroup Graphics Processing Unit, a special processing unit geared towards high-speed parallel processing. \nomeqref {0}
		\nompageref{viii}
  \item [{IP methods}]\begingroup Interior point methods for convex optimization\nomeqref {0}
		\nompageref{viii}
  \item [{RBF}]\begingroup Radial basis function, one of the most popular kernel functions for SVM. \nomeqref {0}
		\nompageref{viii}
  \item [{RKHS}]\begingroup Reproducible Kernel Hilbert Spaces\nomeqref {0}
		\nompageref{viii}
  \item [{SGD}]\begingroup Stochastic Gradient Descent. Simple optimization method for minimizing an objective function that is written as a sum of differentiable functions.\nomeqref {0}
		\nompageref{viii}
  \item [{SMO}]\begingroup Sequential minimal optimization, a decomposition method for SVM training. \nomeqref {0}
		\nompageref{viii}
  \item [{SVM}]\begingroup Support Vector Machines, a set of learning methods used mainly for classification and regression.\nomeqref {0}
		\nompageref{viii}
  \item [{VC Dimension}]\begingroup Vapnikâ€“Chervonenkis dimension is a measure of the capacity of a statistical classification algorithm, defined as the cardinality of the largest set of points that the algorithm can shatter.\nomeqref {0}
		\nompageref{viii}

\end{thenomenclature}
